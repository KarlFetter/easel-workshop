# R for Reproducible Scientific Analysis (Jupyter)

In this session we assume that there is a basic knowledge of R and it's syntax. There is also a parallel session running on [Data Carpentry for Ecology](https://nioo.knaw.nl/en/open-science-tools) that provides an in-depth presentation of R. The material presented here is based on the following lessons:
- [Software Carpentry: Programming with R](http://swcarpentry.github.io/r-novice-inflammation/)
- [Software Carpentry: R for Reproducible Scientific Analysis](http://swcarpentry.github.io/r-novice-gapminder/)
- [Data Carpentry: R for data analysis and visualization of Ecological Data](http://www.datacarpentry.org/R-ecology-lesson/)

## Data

We will use our new Jupyter environment to analyze the [bird ringing data Netherlands 1960-1990 part 1, led by  Henk van der Jeugd](https://doi.org/10.17026/dans-2ch-6s6r). The `csv` file containing this data available though this workshop is [here](files/Export_DANS_Parels_van_Datasets_Vogeltrekstation.csv), and the original source is [here](https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:63027).


## Code and document

Let's try and have an general analysis of the data we downloaded earlier. First, we'll need to import some libraries that will help us with the analysis process.

```
# Data Analysis Libraries
library(dplyr)
library(tidyr)

# Community Ecology Package
library(vegan)

# Visualization Libraries
library(ggplot2)
```

By running the above commands in a single cell, you should be able to see the loaded libraries. If there are errors, you can install the packages with the command `install.packages("dplyr", "tidyr", "vegan", "ggplot2");`. However, bear in mind that they may require a few minutes until the installation is complete (see also [Setup](0.Setup.md)).

The next step is to load the data. It should be already downloaded and available within the directory `files` (change the following code, if the path to the file in your system is different).

```
dansDataSet <- read.csv(file = "files/Export_DANS_Parels_van_Datasets_Vogeltrekstation.csv", header = TRUE)

head(dansDataSet)
summary(dansDataSet)
```
We observe that even though the data was loaded correctly, they are not used in the best possible way. For example, `Ringnumber`, `CatchDate` and `Age` are used as words rather than as numeric values. Also, missing values are defined as `NULL` which is not recognized as such by R (the correct value would be `NA`). The next cell will tidy the data, so that that each attribute is treated as originally intended.

```
dansDataSet <- data.frame(lapply(dansDataSet, function(x) { gsub("NULL", NA, x) }))

dansDataSet$Ringnumber <- as.numeric(dansDataSet$Ringnumber)
dansDataSet$CatchDate <- as.Date(dansDataSet$CatchDate)
dansDataSet$Age <- as.numeric(dansDataSet$Age)
dansDataSet$Broodsize <- as.numeric(dansDataSet$Broodsize)
dansDataSet$PullusAge <- as.numeric(dansDataSet$PullusAge)

summary(dansDataSet)
```

We can see that the data is much more better formatted and useful for further analysis.

### Creating subsets and some indexes

Let's now create two distinct subsets of the original data. Subset #1 `dansDataSet_Kennemerduinen` will contain all the records for which `Own.location.description` is `Kennemerduinen`. Then we will group the records by species and catch date, and calculate the average age per species.

```
dansDataSet_Kennemerduinen <- dansDataSet %>%
  filter(Own.location.description == "Kennemerduinen") %>%
  group_by(Species, CatchDate) %>%
  summarise(Age.Avg = mean(Age))

dansDataSet_Kennemerduinen_matrix <- dansDataSet_Kennemerduinen %>%
  spread(CatchDate, Age.Avg)
```

Our second subset will create a matrix of the distribution of species across the different locations. This will consequently allow us to calculate some diversity indexes.

```
dansDataSet_distribution <- dansDataSet %>%
  na.omit() %>%
  group_by(Species, Location) %>%
  summarise(count = n())

dansDataSet_distribution_matrix <- dansDataSet_distribution %>%
  spread(Location, count)
```

### Using the `vegan` package

We will now use the [`vegan`](https://cran.r-project.org/web/packages/vegan/index.html) package to calculate the diversity in the locations.

```
dansDataSet_distribution_zero <- dansDataSet_distribution_matrix
dansDataSet_distribution_zero[is.na(dansDataSet_distribution_zero)] <- 0
dansDataSet_distribution_zero <- t(dansDataSet_distribution_zero[,2:8])
```

#### Calculating diversity: **Shannon**, **Simpson** and **Inverted Simpson**.

For each of these indexes, we are going to call the corresponding function from vegan, using the default parameters:

Shannon or Shannon–Weaver (or Shannon–Wiener) index is defined as:

$$H = -\sum_{n=1}^{R} p_i ln_b(p_i) = 1$$

where $p_i$ is the proportional abundance of species $i$ and $b$ is the base of the logarithm. It is most popular to use natural logarithms, but some argue for base $b = 2$.

Both variants of Simpson's index are based on $D = \sum_{n=1}^{R}p_i^2$. Choice simpson returns $1-D$ and invsimpson returns $\frac{1}{D}$.

```
Hshannon <- diversity(dansDataSet_distribution_zero, index = "shannon", MARGIN = 1, base = exp(1))
simp <- diversity(dansDataSet_distribution_zero, "simpson", MARGIN = 1)
invsimp <- diversity(dansDataSet_distribution_zero, "inv", MARGIN = 1)
```

#### Calculating species richness

The function `rarefy` gives the expected species richness in random subsamples of size sample from the community. The size of sample should be smaller than total community size, but the function will silently work for larger sample as well and return non-rarefied species richness (and standard error equal to 0). If sample is a vector, `rarefaction` is performed for each sample size separately. Rarefaction can be performed only with genuine counts of individuals. The function rarefy is based on Hurlbert's (1971) formulation, and the standard errors on Heck et al. (1975).

```
r.2 <- rarefy(dansDataSet_distribution_zero, 2)
```

####  Calculating `fisher.alpha`

This function estimates the $a$ parameter of Fisher's logarithmic series. The estimation is possible only for genuine counts of individuals. The function can optionally return standard errors of $a$. These should be regarded only as rough indicators of the accuracy: the confidence limits of $a$ are strongly non-symmetric and the standard errors cannot be used in Normal inference.

```
alpha <- fisher.alpha(dansDataSet_distribution_zero)
```

#### Richness and Evenness

Species **richness** (S) is calculated by `specnumber` which finds the number of species. If MARGIN is set to 2, it finds frequencies of species. **Pielou's evenness** (J) is calculated by $\frac{H_shannon}{log(S)}$.

```
S <- specnumber(dansDataSet_distribution_zero, MARGIN = 1) ## rowSums(BCI > 0) does the same...
J <- Hshannon/log(S)
```

## Results

Finally, let's also create some plots. First of all, let's create a plot based on our first subset, showing for each species and capture dates, the average age of the species captured.

```
ggplot(data=dansDataSet_Kennemerduinen, aes(x=CatchDate, y=Species, color=Age.Avg)) + geom_point(aes(size=Age.Avg))
```

We can also create a plot based on the second subset. In this case, let's see how the distribution of species across the seven locations looks like.

```
ggplot(data=dansDataSet_distribution, aes(x=Species, y=Location, color=Species)) + geom_point(aes(size=count)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Finally, let's have a figure showing all 5 indexes together.

```
pairs(cbind(Hshannon, simp, invsimp, r.2, alpha), pch="+", col="blue")
```

# Conclusions

Jupyter is awesome!


## References / Sources

- [Software Carpentry: Programming with R](http://swcarpentry.github.io/r-novice-inflammation/)
- [Software Carpentry: R for Reproducible Scientific Analysis](http://swcarpentry.github.io/r-novice-gapminder/)
- [Data Carpentry: R for data analysis and visualization of Ecological Data](http://www.datacarpentry.org/R-ecology-lesson/)
